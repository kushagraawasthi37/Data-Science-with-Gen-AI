"""
===========================================================
üìå DATA ENCODING IN MACHINE LEARNING (INTERVIEW READY)
===========================================================

Data Encoding = Converting categorical (non-numeric) data
into numerical format so ML algorithms can understand it.

Why encoding is required?
-------------------------
‚Ä¢ ML models work with numbers, not text
‚Ä¢ Distance-based models (KNN, SVM, Linear models) need numeric input
‚Ä¢ Proper encoding prevents misleading relationships

This file covers:
1Ô∏è‚É£ Label Encoding
2Ô∏è‚É£ Ordinal Encoding
3Ô∏è‚É£ One-Hot Encoding
4Ô∏è‚É£ Dummy Variable Trap
5Ô∏è‚É£ When to use which encoding (INTERVIEW GOLD ‚≠ê)

===========================================================
"""

# =========================================================
# IMPORTS
# =========================================================
import pandas as pd
import numpy as np

from sklearn.preprocessing import (
    LabelEncoder,
    OrdinalEncoder,
    OneHotEncoder
)

# =========================================================
# SAMPLE DATASET
# =========================================================
df = pd.DataFrame({
    "Gender": ["Male", "Female", "Female", "Male"],
    "City": ["Delhi", "Mumbai", "Delhi", "Pune"],
    "Education": ["High School", "Bachelor", "Master", "Bachelor"]
})

print("Original DataFrame:\n", df)


# =========================================================
# 1Ô∏è‚É£ LABEL ENCODING
# =========================================================
"""
What is Label Encoding?
----------------------
‚Ä¢ Assigns a unique integer to each category
‚Ä¢ Example: Male ‚Üí 1, Female ‚Üí 0

‚ö†Ô∏è Problem:
-----------
Creates a FALSE ORDER (model may think 1 > 0)

Best used when:
---------------
‚Ä¢ Target variable (Y)
‚Ä¢ Binary categorical feature
"""

le = LabelEncoder()

df["Gender_LabelEncoded"] = le.fit_transform(df["Gender"])

print("\nLabel Encoded Gender:\n", df)


# =========================================================
# 2Ô∏è‚É£ ORDINAL ENCODING
# =========================================================
"""
What is Ordinal Encoding?
-----------------------
‚Ä¢ Used when categories have a MEANINGFUL ORDER
‚Ä¢ Example:
    High School < Bachelor < Master

‚úî Correctly preserves ranking
‚ùå Distances may still be misleading

Best used when:
---------------
‚Ä¢ Education levels
‚Ä¢ Ratings (Low, Medium, High)
"""

education_order = [["High School", "Bachelor", "Master"]]

oe = OrdinalEncoder(categories=education_order)

df["Education_OrdinalEncoded"] = oe.fit_transform(
    df[["Education"]]
)

print("\nOrdinal Encoded Education:\n", df)


# =========================================================
# 3Ô∏è‚É£ ONE-HOT ENCODING
# =========================================================
"""
What is One-Hot Encoding?
-----------------------
‚Ä¢ Creates separate binary columns (0/1) for each category
‚Ä¢ No false ordering
‚Ä¢ Safe for most ML algorithms

‚ùå Cons:
-------
‚Ä¢ High dimensionality for large categories
‚Ä¢ Curse of Dimensionality risk

Best used when:
---------------
‚Ä¢ Nominal data (City, Color, Country)
‚Ä¢ No natural order exists
"""

ohe = OneHotEncoder(
    sparse=False,          # return numpy array instead of sparse matrix
    drop=None              # don't drop any column yet
)

city_encoded = ohe.fit_transform(df[["City"]])

city_encoded_df = pd.DataFrame(
    city_encoded,
    columns=ohe.get_feature_names_out(["City"])
)

# Merge with original dataframe
df_ohe = pd.concat([df, city_encoded_df], axis=1)

print("\nOne-Hot Encoded City:\n", df_ohe)


# =========================================================
# 4Ô∏è‚É£ DUMMY VARIABLE TRAP
# =========================================================
"""
What is Dummy Variable Trap?
---------------------------
‚Ä¢ Occurs when all dummy variables are included
‚Ä¢ Causes multicollinearity in Linear Models

Solution:
---------
‚Ä¢ Drop one dummy column (k-1 rule)

NOTE:
-----
‚Ä¢ Tree-based models (RandomForest, XGBoost) are immune
‚Ä¢ Linear / Logistic Regression are affected
"""

ohe_drop = OneHotEncoder(
    sparse=False,
    drop="first"   # drops first category automatically
)

city_encoded_safe = ohe_drop.fit_transform(df[["City"]])

city_encoded_safe_df = pd.DataFrame(
    city_encoded_safe,
    columns=ohe_drop.get_feature_names_out(["City"])
)

df_safe = pd.concat([df, city_encoded_safe_df], axis=1)

print("\nOne-Hot Encoding after avoiding Dummy Variable Trap:\n", df_safe)


# =========================================================
# 5Ô∏è‚É£ INTERVIEW: WHICH ENCODING TO USE? ‚≠ê
# =========================================================
"""
üìå QUICK INTERVIEW DECISION GUIDE
--------------------------------

Binary category?
‚Üí Label Encoding

Ordered category?
‚Üí Ordinal Encoding

Unordered category (Nominal)?
‚Üí One-Hot Encoding

Linear / Logistic Regression?
‚Üí One-Hot Encoding (drop one)

Tree-based models?
‚Üí Label Encoding usually works fine

Large cardinality feature?
‚Üí Target Encoding / Frequency Encoding (Advanced)

===========================================================
END OF FILE üöÄ
===========================================================
"""
